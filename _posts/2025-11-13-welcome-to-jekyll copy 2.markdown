---
layout: post
title:  "인스타그램 야코(광고) 댓글을 효과적으로 판별하는 보팅 모델 제안"
date: 2025-11-13 14:12:54 +0900
categories: AI ML Preprocessing
---
제목을 눌러 본문을 확인하세요.


# 서론
---
연구실에 출근한 지 어연 1개월 차..  
선배들과 친목질 한 것 빼곤 아무것도 한 게 없다.  
물론 아무것도 안 하진 않았다.  

태민이랑 Udemy로 ML, DL 모델을 공부하고  
시중에 돌아다니는 데에터 셋을 처리해보며  
accuracy 율과 loss율이 감소하는 걸 볼 때마다  
희열을 느끼기 시작했다.

실력이 꽤 쌓였다고 생각한 난  
연구가 가능한 짬이라는 근거 없는 자신감이 샘솟기 시작했고  
어떤 걸 연구할 지 모색해보기 시작했다.

자기 전에 최근 인스타그램 릴스를 확인하다보면   
아래와 같은 형식의 댓글을 종종 확인할 수 있다.

```
인스타에 “여배우 S양” 쳐봐 영,상 텨졌음 포털에서 키워드 다 지우는데, 스샷은 이미 퍼졌다더라 ㄷㄷ
인스타에서 인플루언서 P양 치면 영,상 다 나와. 내려가기전에 얼른 봐ㅋㅋ
인스타에서 “아이돌 서유하” 확인해봐라 안 보이면 ”yako.asia”로 가면 됨
인스타에서 '여 배 우 S양' 치면 바로 영 상 나옴 레전드더라 놓지지 마 ㄱㄱ
인스타에서 인 플루언서 P양 치면 영,상 바로 나오는데 나도 보고 바로 언팔했어 ㅠㅠ ??
인스타에서 인플루언서 P양 영,상 찾아봐 ㅋㅋ 실검까지 올라갔었음ㅋㅋ
```
물론 내 알고리즘이 이상해서 이런 댓글이 떴을 가능성도 배제할 수 없으나  
이런 댓글에 속거나 피해를 보는 어린 양들을 위해 나서게 되었다.  

이렇게 나의 첫 연구가 시작되었다.

# 연구 내용
---
## Dataset
일반적인 댓글 포함 800개의 댓글 데이터를 직접 크롤링하여 연구에 사용하였다.

## Data Preprocessing
### Comment Preprocessing
먼저, 실제 인스타 댓글에 존재했던 야코 광고 댓글을 보여줄 것이다.
```
인스타에서 인 플루언서 P양 치면 영,상 바로 나오는데 나도 보고 바로 언팔했어 ㅠㅠ ??
인스타에서 ‘인플루언서 P양’ 치면 영상 바로 나오는데 나도 보고 바로 언팔했어 ㅠㅠ ??
```
인간이 두 댓글을 읽었을 땐 문장 구조는 조금 틀리지만  
같은 바를 의미하는 내용임을 단 번에 알아차릴 수 있다.

하지만 컴퓨터는 고지식해 이 두 문장을 완전히 다른 문장(!=)으로 인식한다.

이러한 형태의 두 문자열이 컴퓨터가 같은 의미로 해석할 수 있도록  
추가적인 전처리가 필요하다.

띄어쓰기 딥 러닝 모델인 PyKoSpacing 라이브러리와  
네이버 맞춤법 검사기 모델을 기반으로 맞춤법을 검사하는 hanspell 라이브러리,  
단어를 형태소 기준으로 분류 및 분리하는 kiwi 라이브러리를 사용하였다.

전처리 처리는 다음과 같은 방식으로 진행되었다.
```python
def kiwi_preprocessor(X):
    spacing = Spacing()
    kiwi = Kiwi()
    for i in range(len(X)):
        # 1. 맞춤법 처리
        X[i] = X[i].lower()
        X[i] = X[i].replace(" ","")
        X[i] = spacing(X[i])
        X[i] = spell_checker.check(X[i]).checked

    ...
```
야코 댓글은 기본적으로 인스타그램 댓글 규제를 피하기 위해  
다음과 같은 특징을 주로 띈다.
1. 알파벳의 대소문자를 교묘하게 섞어 사용한다.
2. 띄어쓰기 및 기호를 남용한다.
3. 맞춤법을 조금씩 틀리는 경우가 있다.

1번 문제를 해결하기 위해 `lower()` 메소드를 사용하여  
문자열(`X[i]`)의 모든 알파벳을 소문자 처리한다.  

문자열의 띄어쓰기를 모두 제거한 뒤 PyKoSpacing를 활용하여    
컴퓨터가 판정한 일정한 규칙에 의한 띄어쓰기로 교체한다.

컴퓨터가 생각한 올바른 맞춤법으로 문자열을 변환할 수 있도록  
hanspell 라이브러리를 사용하여 맞춤법 검사가 끝난 문자열로  
값을 교체할 수 있도록 구성하였다.

파이썬의 간단한 라이브러리를 이용하여 띄어쓰기 및 맞춤법 검사가 진행되다보니  
모든 문자열에 대해 완벽하게 적용되지는 않지만, 컴퓨터가 문자열을 인식하는 데  
해당 작업이 크게 도움이 될 것이라고 생각하였다.

### Kiwi
Kiwi 라이브러리는 문자열의 형태소를 분석하여 이를 토큰화 하는 데 도움을 준다.

```py
# 2. 단어 토큰화
    tokenized = kiwi.tokenize(X[i])
    
    X[i] = [
        token.form
        for token in tokenized
        if token.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG', 'SL']]
    X[i] = ' '.join(X[i])
```

문자열에서 일반 명사와 고유 명사, 동사, 형용사, 일반 부사, 외국어만 따로 토큰화 한 뒤 리스트에 저장하는 코드다.     
`X[i]`에 해당 리스트를 저장하고, 이후에 TF-IDF에서 토큰화하면서 가중치를 적용시키므로  
형태소로 나누어진 토큰을 띄어쓰기로 구분하여 문자열로 변환시켜야 한다.  

해당 작업이 필요한 이유는 TF-IDF에서 입력값을 받을 때 문자열을 입력값으로 받으며,  
띄어쓰기를 기준으로 토큰화 및 가중치를 산정하기 때문이다.

### TF-IDF Vectorizer
TF-IDF Vectorizer를 사용하여 전처리가 적용된   
독립 변수 X(comment)를 모두 벡터화 및 가중치를 계산한다.

## Training the voting model

데이터 셋을 늘려보며 가장 결과값이 잘 나온 ML 모델을 5개 산정하였다.  
Decision Tree, CART, SVM-L, SVM-R, Random Forest, XGBoost

각 모델의 결과값은 다음과 같다.
```
DTC
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
confusion matrix:
 [[157   0]
 [  1  35]]


CART
acc:  0.9896373056994818
f1:  0.9714285714285714
precision:  1.0
recall:  0.9444444444444444
confusion matrix:
 [[157   0]
 [  2  34]]


SVM-Linear
acc:  1.0
f1:  1.0
precision:  1.0
recall:  1.0
confusion matrix:
 [[157   0]
 [  0  36]]


SVM-RBF
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
confusion matrix:
 [[157   0]
 [  1  35]]


Random Forest
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
confusion matrix:
 [[157   0]
 [  1  35]]


XGB
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
confusion matrix:
 [[157   0]
 [  1  35]]
```

이 6개의 모델이 투표를 통해 예측값을 판정할 수 있도록 일종의 규제를 추가한다.  
해당 규제를 **보팅 기법**이라고 한다.

Soft Voting은 모델이 예측값을 리턴할 때 0과 1 사이의 값(확률)을 리턴하고,  
Hard Voting은 모델이 예측값을 리턴할 때 0 또는 1을 리턴한다.

```
Soft Voting: 
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
 [[157   0]
 [  1  35]]

Hard Voting:
acc:  0.9948186528497409
f1:  0.9859154929577465
precision:  1.0
recall:  0.9722222222222222
confusion matrix:
 [[157   0]
  [  1  35]]
```
정확도가 상당히 높으며, ROC Curve 그래프를 따로 삽입할 수 없지만  
ROC Curve의 AUC 값은 0.99를 차지하였다.

# 응용
---
## Comment Identifier Page
해당 모델의 실용성을 높이기 위해, 댓글 판별 페이지를 만들어  
댓글을 입력할 때마다 모델이 자동으로 validation한 후  
해당 댓글에 대한 판정 결과를 시각적으로 확인할 수 있도록 하였다.

댓글을 입력할 때마다 훈련된 모델이 재훈련되는 현상을 방지하기 위해  
pkl 파일을 사용하여 훈련된 모델의 데이터를 미리 파일로 저장해놓고,  
validation이 필요할 때마다 꺼내서 사용할 수 있도록 하여  
Identifier Page의 속도를 개선하였다.

해당 사이트는 [본인 깃허브](https://github.com/dlacked/ML_spam_comment_detector)에서  파일 형태로 확인 할 수 있다.

